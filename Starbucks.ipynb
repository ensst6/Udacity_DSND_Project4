{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Exercise: Starbucks\n",
    "<br>\n",
    "\n",
    "<img src=\"https://opj.ca/wp-content/uploads/2018/02/New-Starbucks-Logo-1200x969.jpg\" width=\"200\" height=\"200\">\n",
    "<br>\n",
    "<br>\n",
    " \n",
    "#### Background Information\n",
    "\n",
    "The dataset you will be provided in this portfolio exercise was originally used as a take-home assignment provided by Starbucks for their job candidates. The data for this exercise consists of about 120,000 data points split in a 2:1 ratio among training and test files. In the experiment simulated by the data, an advertising promotion was tested to see if it would bring more customers to purchase a specific product priced at $10. Since it costs the company 0.15 to send out each promotion, it would be best to limit that promotion only to those that are most receptive to the promotion. Each data point includes one column indicating whether or not an individual was sent a promotion for the product, and one column indicating whether or not that individual eventually purchased that product. Each individual also has seven additional features associated with them, which are provided abstractly as V1-V7.\n",
    "\n",
    "#### Optimization Strategy\n",
    "\n",
    "Your task is to use the training data to understand what patterns in V1-V7 to indicate that a promotion should be provided to a user. Specifically, your goal is to maximize the following metrics:\n",
    "\n",
    "* **Incremental Response Rate (IRR)** \n",
    "\n",
    "IRR depicts how many more customers purchased the product with the promotion, as compared to if they didn't receive the promotion. Mathematically, it's the ratio of the number of purchasers in the promotion group to the total number of customers in the purchasers group (_treatment_) minus the ratio of the number of purchasers in the non-promotional group to the total number of customers in the non-promotional group (_control_).\n",
    "\n",
    "$$ IRR = \\frac{purch_{treat}}{cust_{treat}} - \\frac{purch_{ctrl}}{cust_{ctrl}} $$\n",
    "\n",
    "\n",
    "* **Net Incremental Revenue (NIR)**\n",
    "\n",
    "NIR depicts how much is made (or lost) by sending out the promotion. Mathematically, this is 10 times the total number of purchasers that received the promotion minus 0.15 times the number of promotions sent out, minus 10 times the number of purchasers who were not given the promotion.\n",
    "\n",
    "$$ NIR = (10\\cdot purch_{treat} - 0.15 \\cdot cust_{treat}) - 10 \\cdot purch_{ctrl}$$\n",
    "\n",
    "For a full description of what Starbucks provides to candidates see the [instructions available here](https://drive.google.com/open?id=18klca9Sef1Rs6q8DW4l7o349r8B70qXM).\n",
    "\n",
    "Below you can find the training data provided.  Explore the data and different optimization strategies.\n",
    "\n",
    "#### How To Test Your Strategy?\n",
    "\n",
    "When you feel like you have an optimization strategy, complete the `promotion_strategy` function to pass to the `test_results` function.  \n",
    "From past data, we know there are four possible outomes:\n",
    "\n",
    "Table of actual promotion vs. predicted promotion customers:  \n",
    "\n",
    "<table>\n",
    "<tr><th></th><th colspan = '2'>Actual</th></tr>\n",
    "<tr><th>Predicted</th><th>Yes</th><th>No</th></tr>\n",
    "<tr><th>Yes</th><td>I</td><td>II</td></tr>\n",
    "<tr><th>No</th><td>III</td><td>IV</td></tr>\n",
    "</table>\n",
    "\n",
    "The metrics are only being compared for the individuals we predict should obtain the promotion – that is, quadrants I and II.  Since the first set of individuals that receive the promotion (in the training set) receive it randomly, we can expect that quadrants I and II will have approximately equivalent participants.  \n",
    "\n",
    "Comparing quadrant I to II then gives an idea of how well your promotion strategy will work in the future. \n",
    "\n",
    "Get started by reading in the data below.  See how each variable or combination of variables along with a promotion influences the chance of purchasing.  When you feel like you have a strategy for who should receive a promotion, test your strategy against the test dataset used in the final `test_results` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in packages\n",
    "from itertools import combinations\n",
    "\n",
    "from test_results import test_results, score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, recall_score, precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from statsmodels.stats import proportion as proptests\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import fisher_exact\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Promotion</th>\n",
       "      <th>purchase</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.443518</td>\n",
       "      <td>-1.165083</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.159350</td>\n",
       "      <td>-0.645617</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.431659</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.588914</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.044331</td>\n",
       "      <td>-0.385883</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Promotion  purchase  V1         V2        V3  V4  V5  V6  V7\n",
       "0   1        No         0   2  30.443518 -1.165083   1   1   3   2\n",
       "1   3        No         0   3  32.159350 -0.645617   2   3   2   2\n",
       "2   4        No         0   2  30.431659  0.133583   1   1   4   2\n",
       "3   5        No         0   0  26.588914 -0.212728   2   1   4   2\n",
       "4   8       Yes         0   3  28.044331 -0.385883   1   1   2   2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the training data\n",
    "train_data = pd.read_csv('./training.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84534 entries, 0 to 84533\n",
      "Data columns (total 10 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   ID         84534 non-null  int64  \n",
      " 1   Promotion  84534 non-null  object \n",
      " 2   purchase   84534 non-null  int64  \n",
      " 3   V1         84534 non-null  int64  \n",
      " 4   V2         84534 non-null  float64\n",
      " 5   V3         84534 non-null  float64\n",
      " 6   V4         84534 non-null  int64  \n",
      " 7   V5         84534 non-null  int64  \n",
      " 8   V6         84534 non-null  int64  \n",
      " 9   V7         84534 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(1)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Cells for you to work and document as necessary - \n",
    "# definitely feel free to add more cells as you need\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>purchase</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>62970.972413</td>\n",
       "      <td>0.012303</td>\n",
       "      <td>1.500662</td>\n",
       "      <td>29.973600</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>1.679608</td>\n",
       "      <td>2.327643</td>\n",
       "      <td>2.502898</td>\n",
       "      <td>1.701694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36418.440539</td>\n",
       "      <td>0.110234</td>\n",
       "      <td>0.868234</td>\n",
       "      <td>5.010626</td>\n",
       "      <td>1.000485</td>\n",
       "      <td>0.466630</td>\n",
       "      <td>0.841167</td>\n",
       "      <td>1.117349</td>\n",
       "      <td>0.457517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.104007</td>\n",
       "      <td>-1.684550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31467.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.591501</td>\n",
       "      <td>-0.905350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62827.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>29.979744</td>\n",
       "      <td>-0.039572</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>94438.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>33.344593</td>\n",
       "      <td>0.826206</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>126184.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>50.375913</td>\n",
       "      <td>1.691984</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID      purchase            V1            V2            V3  \\\n",
       "count   84534.000000  84534.000000  84534.000000  84534.000000  84534.000000   \n",
       "mean    62970.972413      0.012303      1.500662     29.973600      0.000190   \n",
       "std     36418.440539      0.110234      0.868234      5.010626      1.000485   \n",
       "min         1.000000      0.000000      0.000000      7.104007     -1.684550   \n",
       "25%     31467.250000      0.000000      1.000000     26.591501     -0.905350   \n",
       "50%     62827.500000      0.000000      2.000000     29.979744     -0.039572   \n",
       "75%     94438.750000      0.000000      2.000000     33.344593      0.826206   \n",
       "max    126184.000000      1.000000      3.000000     50.375913      1.691984   \n",
       "\n",
       "                 V4            V5            V6            V7  \n",
       "count  84534.000000  84534.000000  84534.000000  84534.000000  \n",
       "mean       1.679608      2.327643      2.502898      1.701694  \n",
       "std        0.466630      0.841167      1.117349      0.457517  \n",
       "min        1.000000      1.000000      1.000000      1.000000  \n",
       "25%        1.000000      2.000000      2.000000      1.000000  \n",
       "50%        2.000000      2.000000      3.000000      2.000000  \n",
       "75%        2.000000      3.000000      4.000000      2.000000  \n",
       "max        2.000000      4.000000      4.000000      2.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can try logistic regression & maybe another ML model\n",
    "# remember to make dummy vars for V1, V4-V7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umahp/data_science/dsenv/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# recode Promotion\n",
    "train_data['promo_cd'] = 0\n",
    "train_data['promo_cd'].loc[train_data['Promotion']=='Yes'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42364"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "42364"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make sure it worked\n",
    "n_promo = train_data[train_data['Promotion']=='Yes']['Promotion'].count()\n",
    "display(n_promo)\n",
    "display(train_data['promo_cd'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at whether the groups are effectively randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5011474672912675"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# are promo groups balanced?\n",
    "size = train_data.shape[0]\n",
    "prop1 = n_promo/size\n",
    "display(prop1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5068143028294426"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test it\n",
    "p_exact = proptests.binom_test(n_promo, size) # defaults to null p = 0.5 & two-sided\n",
    "display(p_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportions receiving or not receiving the promotion are statistically similar.  \n",
    "Does receipt of promotion increase likelihood of purchase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[41851, 41643], [319, 721]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.007564619397676073"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.017019167217448776"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2.2714773590145283, 1.0678851684503813e-36)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# does the promotion lead to purchases? (2x2 contingency table)\n",
    "# fisher exact test for 2x2 table\n",
    "count11 = train_data[train_data['promo_cd']==1]['purchase'].sum()\n",
    "count01 = train_data[train_data['promo_cd']==0]['purchase'].sum()\n",
    "count10 = train_data[train_data['promo_cd']==1]['purchase'].count()-count11\n",
    "count00 = train_data[train_data['promo_cd']==0]['purchase'].count()-count01\n",
    "table = [[count00, count10], [count01, count11]]\n",
    "prop_no = count01/(count00+count01)\n",
    "prop_yes = count11/(count10+count11)\n",
    "display(table, prop_no, prop_yes)\n",
    "p_stat = fisher_exact(table, alternative='greater')\n",
    "display(p_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = [1.0, 2.0]\n",
    "plt.bar(ind, [100.0*prop_no, 100.0*prop_yes])\n",
    "plt.xticks(ind, ['No', 'Yes'])\n",
    "plt.xlabel('Promotion')\n",
    "plt.ylabel('% Purchasers')\n",
    "plt.title('Purchases by Promotion');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odd ratio is 2.27, p-value basically zero. Receiving promotion tends to lead to a purchase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the association between V1-V7 and purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the net incremental revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2334.5999999999995\n"
     ]
    }
   ],
   "source": [
    "NIR = 10.0*count11 - 0.15*(count11+count10) - 10.0*count01\n",
    "print(NIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it actually is a net loss b/c so many folks in the treatment group didn't purchase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what incremental response rate looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009454547819772702\n"
     ]
    }
   ],
   "source": [
    "IRR = prop_yes - prop_no\n",
    "print(IRR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tiny increase in proportion in the treatment group. But significant since the control is so small (0.0075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it in case I screw this up\n",
    "data_bu = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dummies for the categorical variables\n",
    "# preparatory steps\n",
    "train_data['intercept'] = 1 # needs to be manually added for statsmodels regression\n",
    "train_data[['V1_0', 'V1_1', 'V1_2', 'V1_3']] =pd.get_dummies(train_data['V1'])\n",
    "train_data[['V4_1', 'V4_2']] =pd.get_dummies(train_data['V4'])\n",
    "train_data[['V5_1', 'V5_2', 'V5_3', 'V5_4']] =pd.get_dummies(train_data['V5'])\n",
    "train_data[['V6_1', 'V6_2', 'V6_3', 'V6_4']] =pd.get_dummies(train_data['V6'])\n",
    "train_data[['V7_1', 'V7_2']] =pd.get_dummies(train_data['V7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Promotion</th>\n",
       "      <th>purchase</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>...</th>\n",
       "      <th>V5_1</th>\n",
       "      <th>V5_2</th>\n",
       "      <th>V5_3</th>\n",
       "      <th>V5_4</th>\n",
       "      <th>V6_1</th>\n",
       "      <th>V6_2</th>\n",
       "      <th>V6_3</th>\n",
       "      <th>V6_4</th>\n",
       "      <th>V7_1</th>\n",
       "      <th>V7_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.443518</td>\n",
       "      <td>-1.165083</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.159350</td>\n",
       "      <td>-0.645617</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.431659</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.588914</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.044331</td>\n",
       "      <td>-0.385883</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Promotion  purchase  V1         V2        V3  V4  V5  V6  V7  ...  V5_1  \\\n",
       "0   1        No         0   2  30.443518 -1.165083   1   1   3   2  ...     1   \n",
       "1   3        No         0   3  32.159350 -0.645617   2   3   2   2  ...     0   \n",
       "2   4        No         0   2  30.431659  0.133583   1   1   4   2  ...     1   \n",
       "3   5        No         0   0  26.588914 -0.212728   2   1   4   2  ...     1   \n",
       "4   8       Yes         0   3  28.044331 -0.385883   1   1   2   2  ...     1   \n",
       "\n",
       "   V5_2  V5_3  V5_4  V6_1  V6_2  V6_3  V6_4  V7_1  V7_2  \n",
       "0     0     0     0     0     0     1     0     0     1  \n",
       "1     0     1     0     0     1     0     0     0     1  \n",
       "2     0     0     0     0     0     0     1     0     1  \n",
       "3     0     0     0     0     0     0     1     0     1  \n",
       "4     0     0     0     0     1     0     0     0     1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize the metrics the way the test evaluation is set up, I'm going to use the outcome of people who made a purchase **after** getting the promotion.  Based on the way they have us calculating IRR and NIRR on the test data, identifying members of that group should and sending them promotions should maximize the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    83813\n",
       "1      721\n",
       "Name: promo+purch, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['promo+purch'] = train_data['purchase']*train_data['promo_cd']\n",
    "display(train_data['promo+purch'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the instructions seem to imply we shouldn't peek at the test data til we have the final model, make a train-test split of this dataset. The `stratify` option is to keep the same proportions of the outcome variable in the train & test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data; leave out a reference category for each dummy variable\n",
    "# use stratification to maintain same 0/1 ratio \n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data[['purchase', 'promo_cd','intercept', 'V1_1', 'V1_2', 'V1_3', 'V2',\\\n",
    "                                                               'V3', 'V4_2', 'V5_2', 'V5_3', 'V5_4', \\\n",
    "                                                               'V6_2', 'V6_3', 'V6_4', 'V7_2']],\\\n",
    "                                                                train_data['promo+purch'], train_size = 0.667,\\\n",
    "                                                                stratify = train_data['promo+purch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do graphical exploration and run a univariate logistic regression model for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>promo+purch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.922353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.796687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.955454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.646673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  promo+purch\n",
       "0   0     0.922353\n",
       "1   1     0.796687\n",
       "2   2     0.955454\n",
       "3   3     0.646673"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v1_promopurch = train_data.groupby(['V1'], as_index=False)[['promo+purch']].mean()\n",
    "v1_promopurch['promo+purch'] = v1_promopurch['promo+purch']*100.0\n",
    "display(v1_promopurch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWoElEQVR4nO3deZSldX3n8ffHBmwUIiKoCN00IR1nWhLFFGgkOgomgChgIEg74GiIPYnB5eg4g0dDFDOjkQmeJIKxTZAlyiIY0so2RsElKtCAElZpGRgaMTS7uLB+54/7lF6KWm5193MvVc/7dU6dfpbf/d1v3QP1ub/fs6WqkCR111NGXYAkabQMAknqOINAkjrOIJCkjjMIJKnjDAJJ6jiDQHoSSPLKJGtn0f7iJH/UZk3qDoNArUtyc5KfJXkgyb8nOSnJFqOua1BJKslPmvpvS3JckgWjrmtDJVmY5N4ke06y7+NJzmqWj0yyOsmDSU4aeqFqnUGgYXldVW0BvBgYAz4wsUGSTYZe1S/f+6Qkb56myQub+vcC3gi8dT3eY2S/32Sq6ufAGcCb+rc3IbccOLnZ9EPgL4ATh1qghsYg0FBV1W3A+cAu8Itv23+a5EbgxmbbW5OsSXJ3klVJnjf++qb925LcmOTHST6cZOck30pyf5Izk2zW137Kvtaz/uuBbwC7TDad04x+Xt0sfzDJWUn+Mcn9wJuTbJ3kM0l+mOSeJOdMeP17ktyR5PYkb5mhnJ2TXNr83v+cZOumj3OTvH1Cv1clef0kfZwMHJTkaX3b9qb3t+H85nf+QlWdA9w1Qz2aowwCDVWSRcBrgCv7Nh8IvARY1kxTfAQ4BNgOuAU4fUI3ewO/BbwU+O/ASuAwYBG9gFnevNcgfc22/mXAyyfUP50DgLOArYDPAqcCTwNeADwb+Hhf2+cCzwC2B44Ajk/yzGn6fhPwh/R+t0eAv2m2n0zv8xiv+YVNn+dO7KCqvgXcDvx+3+bDgc9V1SMD/o6a4wwCDcs5Se4Fvgl8Dfhfffs+UlV3V9XPgP8MnFhVV1TVg8D7gN9OsqSv/ceq6v6quga4Gvg/VXVTVd1H71vsrk27Qfoa1BVJ7gG+CPw98JkBX/ftqjqnqh6jFwb7An9cVfdU1cNV9bW+tg8DxzTbzwMeAJ4/Td+nVtXVVfUT4M+AQ5ppnVXArydZ2rQ7HDijqh6aop9TaKaHkvwKvfA6eYq2mocMAg3LgVW1VVXtWFVva/7oj7u1b/l59L65A1BVD9Cbkti+r82/9y3/bJL18QPR0/bVTJfc2wTUG4ETxteTnDCh/hdX1TOraueq+kDzh30Q/b/bIuDuqrpnirZ3TfgW/tO+32Wmvm8BNgW26Zv7PyzJU+iNkE6dpp9TgVc102YHAz+oqkFHPJoHnlQHr9RZ/bfA/SGw4/hKkqcDzwJuW49+p+2rqn6zb99JwMVVddIs+v8JvWme8T4WANtOaNP/u90KbJ1kq6q6dxbvM5VFfcuL6Y0o7mzWT6b3B/6bwE+r6ttTdVJVtyT5Br3ppH1xNNA5jgj0ZHMa8JYkL0ryVHpTSJdU1c0j7msy3wcWJtkvyab0zoR66lSNq+p2elNXJyR5ZpJNk7xiA97/sCTLmgO9xwBnVdWjzXt9G3gM+CumHw2MOxk4EtiD3rGMX0iySZKFwAJgQXPaqV8i5xGDQE8qVfUv9Oa7z6Z3EHNn4NBR9zVF//cBb6N3zOA2eiOEmS4KO5zeN/frgTuAd21ACacCJwE/AhYC75iw/xTgN4B/HKCvs4Gtga80gdXvA/Sm3I6iN2r4GZOc/qu5Kz6YRpqfkrwJWFFVvzPqWvTk5ohAmoea6aK30Tu1VpqWQSDNM0n2BtbRO5vqcyMuR3NAa1NDSU4EXgvcUVW7TLI/wF/Tu7jop8Cbq+qKVoqRJE2pzRHBScA+0+zfF1ja/KwAPtliLZKkKbR2ClhVfX2GKzgPAE6p3pDkO0m2SrLdJGcsPM4222xTS5ZM160kaaLLL7/8zqqaeJ0LMNoLyrbn8VdGrm22PSEIkqygN2pg8eLFrF69eigFStJ8keSWqfbNiYPFVbWyqsaqamzbbScNNEnSehplENzG4y+R34H1u42AJGkDjDIIVgFvSs9LgftmOj4gSdr4WjtGkOQ04JXANs3DO/6c3t0Rqaq/A86jd+roGnqnj870EA5JUgvaPGto+Qz7C/jTtt5fkjSYOXGwWJLUHoNAkjrOIJCkjjMIJKnjfMqQNCRLjjp31CWM3M0f3W/UJWgSjggkqeMMAknqOINAkjrOIJCkjjMIJKnjDAJJ6rhOnT7a9dP3PHVP0mQcEUhSxxkEktRxBoEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHWcQSFLHGQSS1HEGgSR1nEEgSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHWcQSFLHGQSS1HGtBkGSfZLckGRNkqMm2b84yUVJrkxyVZLXtFmPJOmJWguCJAuA44F9gWXA8iTLJjT7AHBmVe0KHAqc0FY9kqTJtTki2B1YU1U3VdVDwOnAARPaFPArzfIzgB+2WI8kaRJtBsH2wK1962ubbf0+CByWZC1wHvD2yTpKsiLJ6iSr161b10atktRZm4z4/ZcDJ1XVXyX5beDUJLtU1WP9japqJbASYGxsrEZQp4AlR5076hJG6uaP7jfqEqRWtDkiuA1Y1Le+Q7Ot3xHAmQBV9W1gIbBNizVJkiZoMwguA5Ym2SnJZvQOBq+a0Ob/AXsBJPmP9ILAuR9JGqLWgqCqHgGOBC4ErqN3dtA1SY5Jsn/T7D3AW5N8DzgNeHNVOfUjSUPU6jGCqjqP3kHg/m1H9y1fC+zRZg2SpOl5ZbEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHWcQSFLHGQSS1HEGgSR1nEEgSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHWcQSFLHGQSS1HEGgSR13CaDNEryMmBJf/uqOqWlmiRJQzRjECQ5FdgZ+C7waLO5AINAkuaBQUYEY8Cyqqq2i5EkDd8gxwiuBp7bdiGSpNGYckSQ5Iv0poC2BK5Ncinw4Pj+qtq//fIkSW2bbmrofw+tCknSyEwZBFX1NYAkOwG3V9XPm/XNgecMpzxJUtsGOVj8eeBlfeuPNtt2a6UiSZrCkqPOHXUJI3XzR/drpd9BDhZvUlUPja80y5u1Uo0kaegGCYJ1SX5xYDjJAcCd7ZUkSRqmQaaG/hj4bJJPNOtrgcPbK0mSNEzTBkGSBcCfVNVLk2wBUFUPDKUySdJQTBsEVfVokt9plg0ASZqHBpkaujLJKnpnCv1kfGNVfaG1qiRJQzPIweKFwF3AnsDrmp/XDtJ5kn2S3JBkTZKjpmhzSJJrk1yT5HODFi5J2jhmHBFU1VvWp+Pm+MLxwO/SO8B8WZJVVXVtX5ulwPuAParqniTPXp/3kiStv0FuQ/0Zevccepyq+sMZXro7sKaqbmr6OR04ALi2r81bgeOr6p6mzzsGrFuStJEMcozgS33LC4HXAz8c4HXbA7f2ra8FXjKhza8DJPlXYAHwwaq6YGJHSVYAKwAWL148wFtLkgY1yNTQ2f3rSU4DvrkR338p8EpgB+DrSX6jqu6dUMNKYCXA2NiYz0WQpI1ofZ5ZvBQYZC7/NmBR3/oOzbZ+a4FVVfVwVf1f4PtN/5KkIZkxCJL8OMn94z/AF4H/MUDflwFLk+yUZDPgUGDVhDbn0BsNkGQbelNFNw1eviRpQw0yNbTl+nRcVY8kORK4kN78/4lVdU2SY4DVVbWq2fd7Sa6ld1fT91bVXevzfpKk9TPdE8qW0ns4zc7AVfT+SE+c2plWVZ0HnDdh29F9ywW8u/mRJI3AdFNDJ9I7Y+gg4Ergb4dSkSRpqKabGtqyqj7dLB+b5IphFCRJGq7pgmBhkl2BNOub969XlcEgSfPAdEFwO3Bc3/qP+taL3r2HJElz3HQPr3/VMAuRJI3GwBeUJXlBm4VIkkZjNlcWn9paFZKkkZlNEGTmJpKkuWamZxb/Ob0DwwGek6T/YrBjWq5NkjQEM91i4ua+5YeBW9orRZI0CjM9vP7k8eUk7+xflyTNDx4jkKSOm00Q7NVaFZKkkRnkUZUkeQ6wWxKAS322sCTNH4M8mOYQ4FLgD4BDgEuSHNx2YZKk4RhkRPB+YLfxUUCSbYF/Ac5qszBJ0nAMcozgKROmgu4a8HWSpDlgkBHBBUkuBE5r1t8AnN9eSZKkYRrkmcXvTXIQsEezaWVV/VO7ZUmShmWgs4aq6uwkXx5vn2Trqrq71cokSUMxYxAk+a/Ah4CfA4/Ru7CsgF9ttzRJ0jAMMiL4b8AuVXVn28VIkoZvkLN/fgD8tO1CJEmjMciI4H3At5JcAjw4vrGq3tFaVZKkoRkkCD4FfBX4N3rHCCRJ88ggQbBpVb279UokSSMxyDGC85OsSLJdkq3Hf1qvTJI0FIOMCJY3/76vb5unj0rSPDHIlcU7DaMQSdJoDHJB2abAnwCvaDZdDHyqqh5usS5J0pAMMjX0SWBT4IRm/fBm2x+1VZQkaXgGCYLdquqFfetfTfK9tgqSJA3XIGcNPZpk5/GVJL8KPNpeSZKkYRr0XkMXJbmJ3g3ndgTe0mpVkqShmXZEkGQB8EJgKfAO4O3A86vqokE6T7JPkhuSrEly1DTtDkpSScZmUbskaSOYNgiq6lFgeVU9WFVXNT8PTveacU2IHA/sCywDlidZNkm7LYF3ApfMunpJ0gYb5BjBvyb5RJKXJ3nx+M8Ar9sdWFNVN1XVQ8DpwAGTtPsw8Jf0nncgSRqyQY4RvKj595i+bQXsOcPrtgdu7VtfC7ykv0ETKIuq6twk752qoyQrgBUAixcvHqBkSdKgBgmCP2jjoTRJngIcB7x5prZVtRJYCTA2NlYbuxZJ6rIpp4aSvC7JOuCqJGuTvGyWfd8GLOpb36HZNm5LYBfg4iQ3Ay8FVnnAWJKGa7pjBP8TeHlVPQ84CPjILPu+DFiaZKckmwGHAqvGd1bVfVW1TVUtqaolwHeA/atq9SzfR5K0AaYLgkeq6nqAqrqE3jf4gVXVI8CRwIXAdcCZVXVNkmOS7L++BUuSNq7pjhE8O8m7p1qvquNm6ryqzgPOm7Dt6CnavnKm/iRJG990QfBpHj8KmLguSZoHpgyCqvrQMAuRJI3GIBeUSZLmMYNAkjrOIJCkjhs4CJK8NMkFSS5OcmCLNUmShmjKg8VJnltVP+rb9G7g9fSeSXAJcE67pUmShmG600f/LskVwMeq6ufAvcDBwGPA/UOoTZI0BFNODVXVgcCVwJeSvAl4F/BU4FnAgUOoTZI0BDM9mOaLwN7AM4B/Ar5fVX9TVeuGUZwkqX3T3X10/yQXARcAVwNvAA5Icnr/w+wlSXPbdMcI/oLeU8Y2By6sqt2B9yRZSu/OpIcOoT5JUsumC4L7gN8HngbcMb6xqm7EEJCkeWO6YwSvp3dgeBPgjcMpR5I0bNPddO5O4G+HWIskaQS8xYQkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHWcQSFLHGQSS1HEGgSR1nEEgSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHWcQSFLHtRoESfZJckOSNUmOmmT/u5Ncm+SqJF9JsmOb9UiSnqi1IEiyADge2BdYBixPsmxCsyuBsar6TeAs4GNt1SNJmlybI4LdgTVVdVNVPQScDhzQ36CqLqqqnzar3wF2aLEeSdIk2gyC7YFb+9bXNtumcgRw/mQ7kqxIsjrJ6nXr1m3EEiVJT4qDxUkOA8aAYyfbX1Urq2qsqsa23Xbb4RYnSfPcJi32fRuwqG99h2bb4yR5NfB+4D9V1YMt1iNJmkSbI4LLgKVJdkqyGXAosKq/QZJdgU8B+1fVHS3WIkmaQmtBUFWPAEcCFwLXAWdW1TVJjkmyf9PsWGAL4PNJvptk1RTdSZJa0ubUEFV1HnDehG1H9y2/us33lyTN7ElxsFiSNDoGgSR1nEEgSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHWcQSFLHGQSS1HEGgSR1nEEgSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHWcQSFLHGQSS1HEGgSR1nEEgSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHddqECTZJ8kNSdYkOWqS/U9Nckaz/5IkS9qsR5L0RK0FQZIFwPHAvsAyYHmSZROaHQHcU1W/Bnwc+Mu26pEkTa7NEcHuwJqquqmqHgJOBw6Y0OYA4ORm+SxgryRpsSZJ0gSbtNj39sCtfetrgZdM1aaqHklyH/As4M7+RklWACua1QeS3NBKxe3bhgm/2zBl7o+3/Pw2nJ/hhpnLn9+OU+1oMwg2mqpaCawcdR0bKsnqqhobdR1zlZ/fhvMz3DDz9fNrc2roNmBR3/oOzbZJ2yTZBHgGcFeLNUmSJmgzCC4DlibZKclmwKHAqgltVgH/pVk+GPhqVVWLNUmSJmhtaqiZ8z8SuBBYAJxYVdckOQZYXVWrgH8ATk2yBribXljMZ3N+emvE/Pw2nJ/hhpmXn1/8Ai5J3eaVxZLUcQaBJHWcQTAkM91uQ1NLcmKSO5JcPepa5qIki5JclOTaJNckeeeoa5pLkixMcmmS7zWf34dGXdPG5jGCIWhut/F94HfpXVh3GbC8qq4daWFzRJJXAA8Ap1TVLqOuZ65Jsh2wXVVdkWRL4HLgQP/7G0xzt4OnV9UDSTYFvgm8s6q+M+LSNhpHBMMxyO02NIWq+jq9s8q0Hqrq9qq6oln+MXAdvav6NYDqeaBZ3bT5mVffoA2C4Zjsdhv+j6iha+7wuytwyYhLmVOSLEjyXeAO4MtVNa8+P4NA6ogkWwBnA++qqvtHXc9cUlWPVtWL6N0hYfck82qK0iAYjkFutyG1ppnbPhv4bFV9YdT1zFVVdS9wEbDPiEvZqAyC4RjkdhtSK5qDnf8AXFdVx426nrkmybZJtmqWN6d30sf1Iy1qIzMIhqCqHgHGb7dxHXBmVV0z2qrmjiSnAd8Gnp9kbZIjRl3THLMHcDiwZ5LvNj+vGXVRc8h2wEVJrqL3pe7LVfWlEde0UXn6qCR1nCMCSeo4g0CSOs4gkKSOMwgkqeMMAknqOINAndTcjXPvCdveleSTzfIFSe5NstFOE0xyUpKDN1Z/0sZiEKirTuOJj0Y9tNkOcCy9c++lec8gUFedBezXXOk9fjO25wHfAKiqrwA/nurFSf5Dkkv71pck+bdm+egklyW5OsnK5sreia+/Ock2zfJYkoub5ac3z1+4NMmVSbxLrVpnEKiTqupu4FJg32bTofSu+B7oCsuquh7YLMlOzaY3AGc0y5+oqt2aZydsDrx2FqW9H/hqVe0OvAo4NsnTZ/F6adYMAnVZ//RQ/7TQoM6kFwDw+CB4VZJLmhHCnsALZtHn7wFHNbc8vhhYCCyeZV3SrGwy6gKkEfpn4ONJXgw8raoun+XrzwA+n+QL9J5fcmOShcAJwFhV3Zrkg/T+mE/0CL/8Ita/P8BBVXXDLGuR1psjAnVW89Spi4ATmf1ogKr6AfAo8Gf8cjQw/kf9zub+/1OdJXQz8FvN8kF92y8E3j5+XCHJrrOtS5otg0BddxrwQiYEQZJvAJ8H9mrueLr3ZC+mFwCH0ZsmGr9f/aeBq+n9Ub9sitd9CPjrJKvphcm4D9N7FOJVSa5p1qVWefdRSeo4RwSS1HEGgSR1nEEgSR1nEEhSxxkEktRxBoEkdZxBIEkd9/8Bm08ve2smWRMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = [1.0, 2.0, 3.0, 4.0]\n",
    "plt.bar(ind, v1_promopurch['promo+purch'])\n",
    "plt.xticks(ind, ['0', '1', '2', '3'])\n",
    "plt.xlabel('V1 value')\n",
    "plt.ylabel('% Promo+Purch')\n",
    "plt.title('Promo+Purch by V1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.049036\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>   <td>0.002</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>promo+purch</td>         <td>AIC:</td>        <td>5537.7380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-05-22 16:13</td>       <td>BIC:</td>        <td>5573.4978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>56384</td>       <td>Log-Likelihood:</td>   <td>-2764.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>3</td>            <td>LL-Null:</td>       <td>-2770.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>56380</td>        <td>LLR p-value:</td>    <td>0.010763</td> \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>        <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>9.0000</td>              <td></td>              <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-4.7066</td>  <td>0.1256</td>  <td>-37.4836</td> <td>0.0000</td> <td>-4.9527</td> <td>-4.4605</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V1_1</th>      <td>-0.1249</td>  <td>0.1477</td>   <td>-0.8462</td> <td>0.3974</td> <td>-0.4143</td> <td>0.1644</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V1_2</th>      <td>0.0958</td>   <td>0.1436</td>   <td>0.6674</td>  <td>0.5045</td> <td>-0.1856</td> <td>0.3773</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V1_3</th>      <td>-0.4040</td>  <td>0.1993</td>   <td>-2.0270</td> <td>0.0427</td> <td>-0.7946</td> <td>-0.0134</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.002    \n",
       "Dependent Variable: promo+purch      AIC:              5537.7380\n",
       "Date:               2021-05-22 16:13 BIC:              5573.4978\n",
       "No. Observations:   56384            Log-Likelihood:   -2764.9  \n",
       "Df Model:           3                LL-Null:          -2770.5  \n",
       "Df Residuals:       56380            LLR p-value:      0.010763 \n",
       "Converged:          1.0000           Scale:            1.0000   \n",
       "No. Iterations:     9.0000                                      \n",
       "-----------------------------------------------------------------\n",
       "             Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
       "-----------------------------------------------------------------\n",
       "intercept   -4.7066    0.1256  -37.4836  0.0000  -4.9527  -4.4605\n",
       "V1_1        -0.1249    0.1477   -0.8462  0.3974  -0.4143   0.1644\n",
       "V1_2         0.0958    0.1436    0.6674  0.5045  -0.1856   0.3773\n",
       "V1_3        -0.4040    0.1993   -2.0270  0.0427  -0.7946  -0.0134\n",
       "================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log1 = sm.Logit(y_train, X_train[['intercept','V1_1', 'V1_2', 'V1_3']])\n",
    "logr1 = log1.fit()\n",
    "logr1.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V1 = 3 is associated with fewer purchases with promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.boxplot(data=train_data, x='promo+purch', y='V2', color='brown')\n",
    "plt.ylabel('V2')\n",
    "plt.xlabel('Promo+Purch');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.049115\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>   <td>0.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>promo+purch</td>         <td>AIC:</td>        <td>5542.5695</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-05-22 16:13</td>       <td>BIC:</td>        <td>5560.4493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>56384</td>       <td>Log-Likelihood:</td>   <td>-2769.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>1</td>            <td>LL-Null:</td>       <td>-2770.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>56382</td>        <td>LLR p-value:</td>     <td>0.12495</td> \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>        <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>9.0000</td>              <td></td>              <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-4.3380</td>  <td>0.2743</td>  <td>-15.8133</td> <td>0.0000</td> <td>-4.8757</td> <td>-3.8004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V2</th>        <td>-0.0140</td>  <td>0.0091</td>   <td>-1.5345</td> <td>0.1249</td> <td>-0.0319</td> <td>0.0039</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000    \n",
       "Dependent Variable: promo+purch      AIC:              5542.5695\n",
       "Date:               2021-05-22 16:13 BIC:              5560.4493\n",
       "No. Observations:   56384            Log-Likelihood:   -2769.3  \n",
       "Df Model:           1                LL-Null:          -2770.5  \n",
       "Df Residuals:       56382            LLR p-value:      0.12495  \n",
       "Converged:          1.0000           Scale:            1.0000   \n",
       "No. Iterations:     9.0000                                      \n",
       "-----------------------------------------------------------------\n",
       "             Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
       "-----------------------------------------------------------------\n",
       "intercept   -4.3380    0.2743  -15.8133  0.0000  -4.8757  -3.8004\n",
       "V2          -0.0140    0.0091   -1.5345  0.1249  -0.0319   0.0039\n",
       "================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log1 = sm.Logit(y_train, X_train[['intercept','V2']])\n",
    "logr1 = log1.fit()\n",
    "logr1.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V2 does not appear to influencing purchase after promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.boxplot(data=train_data, x='promo+purch', y='V3', color='brown')\n",
    "plt.ylabel('V3')\n",
    "plt.xlabel('Promo+Purch');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.049065\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>   <td>0.001</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>promo+purch</td>         <td>AIC:</td>        <td>5536.9603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-05-22 16:14</td>       <td>BIC:</td>        <td>5554.8402</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>56384</td>       <td>Log-Likelihood:</td>   <td>-2766.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>1</td>            <td>LL-Null:</td>       <td>-2770.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>56382</td>        <td>LLR p-value:</td>    <td>0.0047735</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>        <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>9.0000</td>              <td></td>              <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-4.7637</td>  <td>0.0462</td>  <td>-103.1907</td> <td>0.0000</td> <td>-4.8542</td> <td>-4.6732</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V3</th>        <td>-0.1294</td>  <td>0.0460</td>   <td>-2.8147</td>  <td>0.0049</td> <td>-0.2196</td> <td>-0.0393</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.001    \n",
       "Dependent Variable: promo+purch      AIC:              5536.9603\n",
       "Date:               2021-05-22 16:14 BIC:              5554.8402\n",
       "No. Observations:   56384            Log-Likelihood:   -2766.5  \n",
       "Df Model:           1                LL-Null:          -2770.5  \n",
       "Df Residuals:       56382            LLR p-value:      0.0047735\n",
       "Converged:          1.0000           Scale:            1.0000   \n",
       "No. Iterations:     9.0000                                      \n",
       "-----------------------------------------------------------------\n",
       "            Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-----------------------------------------------------------------\n",
       "intercept  -4.7637    0.0462  -103.1907  0.0000  -4.8542  -4.6732\n",
       "V3         -0.1294    0.0460    -2.8147  0.0049  -0.2196  -0.0393\n",
       "================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log1 = sm.Logit(y_train, X_train[['intercept','V3']])\n",
    "logr1 = log1.fit()\n",
    "logr1.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A negative value of V3 influences purchase after promotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V4</th>\n",
       "      <th>promo+purch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.350761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.089643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   V4  promo+purch\n",
       "0   1     0.350761\n",
       "1   2     1.089643"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v4_promopurch = train_data.groupby(['V4'], as_index=False)[['promo+purch']].mean()\n",
    "v4_promopurch['promo+purch'] = v4_promopurch['promo+purch']*100.0\n",
    "display(v4_promopurch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = [1.0, 2.0]\n",
    "plt.bar(ind, v4_promopurch['promo+purch'])\n",
    "plt.xticks(ind, ['1', '2'])\n",
    "plt.xlabel('V4 value')\n",
    "plt.ylabel('% Promo+Purch')\n",
    "plt.title('Promo+Purch by V4');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.048322\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.017</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>promo+purch</td>         <td>AIC:</td>         <td>5453.1927</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-05-22 16:16</td>       <td>BIC:</td>         <td>5471.0726</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>56384</td>       <td>Log-Likelihood:</td>    <td>-2724.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>1</td>            <td>LL-Null:</td>        <td>-2770.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>56382</td>        <td>LLR p-value:</td>    <td>9.9300e-22</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>10.0000</td>             <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-5.6412</td>  <td>0.1252</td>  <td>-45.0496</td> <td>0.0000</td> <td>-5.8866</td> <td>-5.3958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V4_2</th>      <td>1.1324</td>   <td>0.1346</td>   <td>8.4160</td>  <td>0.0000</td> <td>0.8687</td>  <td>1.3961</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.017     \n",
       "Dependent Variable: promo+purch      AIC:              5453.1927 \n",
       "Date:               2021-05-22 16:16 BIC:              5471.0726 \n",
       "No. Observations:   56384            Log-Likelihood:   -2724.6   \n",
       "Df Model:           1                LL-Null:          -2770.5   \n",
       "Df Residuals:       56382            LLR p-value:      9.9300e-22\n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     10.0000                                      \n",
       "------------------------------------------------------------------\n",
       "              Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
       "------------------------------------------------------------------\n",
       "intercept    -5.6412    0.1252  -45.0496  0.0000  -5.8866  -5.3958\n",
       "V4_2          1.1324    0.1346    8.4160  0.0000   0.8687   1.3961\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log1 = sm.Logit(y_train, X_train[['intercept','V4_2']])\n",
    "logr1 = log1.fit()\n",
    "logr1.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V4 influences purchases, with a value of 2 associated with more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V5</th>\n",
       "      <th>promo+purch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.025175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.512886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.099472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.829635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   V5  promo+purch\n",
       "0   1     1.025175\n",
       "1   2     0.512886\n",
       "2   3     1.099472\n",
       "3   4     0.829635"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v5_promopurch = train_data.groupby(['V5'], as_index=False)[['promo+purch']].mean()\n",
    "v5_promopurch['promo+purch'] = v5_promopurch['promo+purch']*100.0\n",
    "display(v5_promopurch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = [1.0, 2.0, 3.0, 4.0]\n",
    "plt.bar(ind, v5_promopurch['promo+purch'])\n",
    "plt.xticks(ind, ['1', '2', '3', '4'])\n",
    "plt.xlabel('V5 value')\n",
    "plt.ylabel('% Promo+Purch')\n",
    "plt.title('Promo+Purch by V5');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.048757\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.008</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>promo+purch</td>         <td>AIC:</td>         <td>5506.2116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-05-22 16:18</td>       <td>BIC:</td>         <td>5541.9713</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>56384</td>       <td>Log-Likelihood:</td>    <td>-2749.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>3</td>            <td>LL-Null:</td>        <td>-2770.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>56380</td>        <td>LLR p-value:</td>    <td>2.8330e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>9.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-4.5797</td>  <td>0.0986</td>  <td>-46.4658</td> <td>0.0000</td> <td>-4.7728</td> <td>-4.3865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V5_2</th>      <td>-0.6181</td>  <td>0.1359</td>   <td>-4.5497</td> <td>0.0000</td> <td>-0.8844</td> <td>-0.3518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V5_3</th>      <td>0.0693</td>   <td>0.1182</td>   <td>0.5858</td>  <td>0.5580</td> <td>-0.1625</td> <td>0.3010</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V5_4</th>      <td>-0.3353</td>  <td>0.2236</td>   <td>-1.4996</td> <td>0.1337</td> <td>-0.7736</td> <td>0.1029</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.008     \n",
       "Dependent Variable: promo+purch      AIC:              5506.2116 \n",
       "Date:               2021-05-22 16:18 BIC:              5541.9713 \n",
       "No. Observations:   56384            Log-Likelihood:   -2749.1   \n",
       "Df Model:           3                LL-Null:          -2770.5   \n",
       "Df Residuals:       56380            LLR p-value:      2.8330e-09\n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     9.0000                                       \n",
       "------------------------------------------------------------------\n",
       "              Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
       "------------------------------------------------------------------\n",
       "intercept    -4.5797    0.0986  -46.4658  0.0000  -4.7728  -4.3865\n",
       "V5_2         -0.6181    0.1359   -4.5497  0.0000  -0.8844  -0.3518\n",
       "V5_3          0.0693    0.1182    0.5858  0.5580  -0.1625   0.3010\n",
       "V5_4         -0.3353    0.2236   -1.4996  0.1337  -0.7736   0.1029\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log1 = sm.Logit(y_train, X_train[['intercept','V5_2', 'V5_3', 'V5_4']])\n",
    "logr1 = log1.fit()\n",
    "logr1.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A V5 value of 2 is associated with fewer purchases after promotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V6</th>\n",
       "      <th>promo+purch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.889375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.803935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.896819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.821685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   V6  promo+purch\n",
       "0   1     0.889375\n",
       "1   2     0.803935\n",
       "2   3     0.896819\n",
       "3   4     0.821685"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v6_promopurch = train_data.groupby(['V6'], as_index=False)[['promo+purch']].mean()\n",
    "v6_promopurch['promo+purch'] = v6_promopurch['promo+purch']*100.0\n",
    "display(v6_promopurch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = [1.0, 2.0, 3.0, 4.0]\n",
    "plt.bar(ind, v6_promopurch['promo+purch'])\n",
    "plt.xticks(ind, ['1', '2', '3', '4'])\n",
    "plt.xlabel('V6 value')\n",
    "plt.ylabel('% Promo+Purch')\n",
    "plt.title('Promo+Purch by V6');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.049105\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>   <td>0.001</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>promo+purch</td>         <td>AIC:</td>        <td>5545.5259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-05-22 16:19</td>       <td>BIC:</td>        <td>5581.2857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>56384</td>       <td>Log-Likelihood:</td>   <td>-2768.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>3</td>            <td>LL-Null:</td>       <td>-2770.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>56380</td>        <td>LLR p-value:</td>     <td>0.33428</td> \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>        <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>9.0000</td>              <td></td>              <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-4.6302</td>  <td>0.0862</td>  <td>-53.7358</td> <td>0.0000</td> <td>-4.7991</td> <td>-4.4613</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V6_2</th>      <td>-0.1479</td>  <td>0.1267</td>   <td>-1.1676</td> <td>0.2430</td> <td>-0.3962</td> <td>0.1004</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V6_3</th>      <td>-0.2330</td>  <td>0.1291</td>   <td>-1.8046</td> <td>0.0711</td> <td>-0.4861</td> <td>0.0201</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V6_4</th>      <td>-0.1332</td>  <td>0.1261</td>   <td>-1.0561</td> <td>0.2909</td> <td>-0.3803</td> <td>0.1140</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.001    \n",
       "Dependent Variable: promo+purch      AIC:              5545.5259\n",
       "Date:               2021-05-22 16:19 BIC:              5581.2857\n",
       "No. Observations:   56384            Log-Likelihood:   -2768.8  \n",
       "Df Model:           3                LL-Null:          -2770.5  \n",
       "Df Residuals:       56380            LLR p-value:      0.33428  \n",
       "Converged:          1.0000           Scale:            1.0000   \n",
       "No. Iterations:     9.0000                                      \n",
       "-----------------------------------------------------------------\n",
       "             Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
       "-----------------------------------------------------------------\n",
       "intercept   -4.6302    0.0862  -53.7358  0.0000  -4.7991  -4.4613\n",
       "V6_2        -0.1479    0.1267   -1.1676  0.2430  -0.3962   0.1004\n",
       "V6_3        -0.2330    0.1291   -1.8046  0.0711  -0.4861   0.0201\n",
       "V6_4        -0.1332    0.1261   -1.0561  0.2909  -0.3803   0.1140\n",
       "================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log1 = sm.Logit(y_train, X_train[['intercept','V6_2', 'V6_3', 'V6_4']])\n",
    "logr1 = log1.fit()\n",
    "logr1.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V6 is not associated with purchasing decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V7</th>\n",
       "      <th>promo+purch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.904152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.831128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   V7  promo+purch\n",
       "0   1     0.904152\n",
       "1   2     0.831128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v7_promopurch = train_data.groupby(['V7'], as_index=False)[['promo+purch']].mean()\n",
    "v7_promopurch['promo+purch'] = v7_promopurch['promo+purch']*100.0\n",
    "display(v7_promopurch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = [1.0, 2.0]\n",
    "plt.bar(ind, v7_promopurch['promo+purch'])\n",
    "plt.xticks(ind, ['1', '2'])\n",
    "plt.xlabel('V7 value')\n",
    "plt.ylabel('% Promo+Purch')\n",
    "plt.title('Promo+Purch by V7');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.049134\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>   <td>0.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>promo+purch</td>         <td>AIC:</td>        <td>5544.7389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-05-22 16:20</td>       <td>BIC:</td>        <td>5562.6188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>56384</td>       <td>Log-Likelihood:</td>   <td>-2770.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>1</td>            <td>LL-Null:</td>       <td>-2770.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>56382</td>        <td>LLR p-value:</td>     <td>0.66739</td> \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>        <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>9.0000</td>              <td></td>              <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-4.7257</td>  <td>0.0826</td>  <td>-57.2376</td> <td>0.0000</td> <td>-4.8875</td> <td>-4.5639</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V7_2</th>      <td>-0.0428</td>  <td>0.0992</td>   <td>-0.4309</td> <td>0.6665</td> <td>-0.2372</td> <td>0.1517</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000    \n",
       "Dependent Variable: promo+purch      AIC:              5544.7389\n",
       "Date:               2021-05-22 16:20 BIC:              5562.6188\n",
       "No. Observations:   56384            Log-Likelihood:   -2770.4  \n",
       "Df Model:           1                LL-Null:          -2770.5  \n",
       "Df Residuals:       56382            LLR p-value:      0.66739  \n",
       "Converged:          1.0000           Scale:            1.0000   \n",
       "No. Iterations:     9.0000                                      \n",
       "-----------------------------------------------------------------\n",
       "             Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
       "-----------------------------------------------------------------\n",
       "intercept   -4.7257    0.0826  -57.2376  0.0000  -4.8875  -4.5639\n",
       "V7_2        -0.0428    0.0992   -0.4309  0.6665  -0.2372   0.1517\n",
       "================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log1 = sm.Logit(y_train, X_train[['intercept','V7_2']])\n",
    "logr1 = log1.fit()\n",
    "logr1.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V7 is not associated with purchasing decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a multivariate logistic regression model to see if all of the variables remain significant in each other's presence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.047847\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.026</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>promo+purch</td>         <td>AIC:</td>         <td>5405.6489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-05-22 16:27</td>       <td>BIC:</td>         <td>5450.3486</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>56384</td>       <td>Log-Likelihood:</td>    <td>-2697.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>4</td>            <td>LL-Null:</td>        <td>-2770.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>56379</td>        <td>LLR p-value:</td>    <td>2.0945e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>10.0000</td>             <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-5.4174</td>  <td>0.1287</td>  <td>-42.0826</td> <td>0.0000</td> <td>-5.6697</td> <td>-5.1651</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V1_3</th>      <td>-0.4018</td>  <td>0.1622</td>   <td>-2.4776</td> <td>0.0132</td> <td>-0.7196</td> <td>-0.0839</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V3</th>        <td>-0.1323</td>  <td>0.0461</td>   <td>-2.8713</td> <td>0.0041</td> <td>-0.2226</td> <td>-0.0420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V4_2</th>      <td>1.1349</td>   <td>0.1346</td>   <td>8.4320</td>  <td>0.0000</td> <td>0.8711</td>  <td>1.3987</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V5_2</th>      <td>-0.6339</td>  <td>0.1073</td>   <td>-5.9063</td> <td>0.0000</td> <td>-0.8443</td> <td>-0.4236</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.026     \n",
       "Dependent Variable: promo+purch      AIC:              5405.6489 \n",
       "Date:               2021-05-22 16:27 BIC:              5450.3486 \n",
       "No. Observations:   56384            Log-Likelihood:   -2697.8   \n",
       "Df Model:           4                LL-Null:          -2770.5   \n",
       "Df Residuals:       56379            LLR p-value:      2.0945e-30\n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     10.0000                                      \n",
       "------------------------------------------------------------------\n",
       "              Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
       "------------------------------------------------------------------\n",
       "intercept    -5.4174    0.1287  -42.0826  0.0000  -5.6697  -5.1651\n",
       "V1_3         -0.4018    0.1622   -2.4776  0.0132  -0.7196  -0.0839\n",
       "V3           -0.1323    0.0461   -2.8713  0.0041  -0.2226  -0.0420\n",
       "V4_2          1.1349    0.1346    8.4320  0.0000   0.8711   1.3987\n",
       "V5_2         -0.6339    0.1073   -5.9063  0.0000  -0.8443  -0.4236\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log1 = sm.Logit(y_train, X_train[['intercept','V1_3', 'V3', 'V4_2', 'V5_2']])\n",
    "logr1 = log1.fit()\n",
    "logr1.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a multivariate logistic regression model. \n",
    "Since the data are sparse, will want to start with weighted logistic regression.\n",
    "Can't find a way to do that with the statsmodel version, so will use sklearn instead.\n",
    "The `ColumnTransformer` step is to scale V3 to mean 1, sd 0 for use an SVM and other scale-dependent models.  \n",
    "What I'm doing here is preliminary feature selection -- just keeping the variables that were significant in the univariate analysis. For the categorical variables, only the dummy variable that was significant is retained, since all the other dummies are effectively equivalent.  \n",
    "For example, for V5, only the dummy variable for the value `2` had a significant regression coefficient. I dropped the dummy variables for `1`, `3`, and `4`. The comparison this is making is `V5 = 2` versus `V5 = 1, 3, or 4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1_3</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4_2</th>\n",
       "      <th>V5_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42450</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.732194</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39436</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.385883</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49424</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.126150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17107</th>\n",
       "      <td>0</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56521</th>\n",
       "      <td>0</td>\n",
       "      <td>0.220161</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1_3        V3  V4_2  V5_2\n",
       "42450     1 -0.732194     1     1\n",
       "39436     0 -0.385883     1     0\n",
       "49424     0 -0.126150     0     0\n",
       "17107     0  0.133583     1     0\n",
       "56521     0  0.220161     1     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.73179378,  1.        ,  1.        ,  1.        ],\n",
       "       [-0.38584589,  0.        ,  1.        ,  0.        ],\n",
       "       [-0.12638507,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.13307586,  0.        ,  1.        ,  0.        ],\n",
       "       [ 0.21956282,  0.        ,  1.        ,  1.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1_3</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4_2</th>\n",
       "      <th>V5_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51895</th>\n",
       "      <td>0</td>\n",
       "      <td>0.220161</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51955</th>\n",
       "      <td>1</td>\n",
       "      <td>0.653050</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11131</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.385883</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56386</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.299306</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.039572</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1_3        V3  V4_2  V5_2\n",
       "51895     0  0.220161     0     1\n",
       "51955     1  0.653050     1     0\n",
       "11131     0 -0.385883     1     0\n",
       "56386     0 -0.299306     1     0\n",
       "5865      0 -0.039572     1     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.22047253,  0.        ,  0.        ,  1.        ],\n",
       "       [ 0.65364963,  1.        ,  1.        ,  0.        ],\n",
       "       [-0.3859754 ,  0.        ,  1.        ,  0.        ],\n",
       "       [-0.29933997,  0.        ,  1.        ,  0.        ],\n",
       "       [-0.03943377,  0.        ,  1.        ,  1.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# just keep the variables that were singificant on univariate analysis\n",
    "X_train2 = X_train[['V1_3', 'V3', 'V4_2', 'V5_2']]\n",
    "X_test2 = X_test[['V1_3', 'V3', 'V4_2', 'V5_2']]\n",
    "# create a set with V3 scaled for SVM\n",
    "ct = ColumnTransformer([(\"std\", StandardScaler(), ['V3'])], remainder = 'passthrough')\n",
    "X_train3 = ct.fit_transform(X_train2)\n",
    "X_test3 = ct.fit_transform(X_test2)\n",
    "display(X_train2.head())\n",
    "display(X_train3[0:5,:])\n",
    "display(X_test2.head())\n",
    "display(X_test3[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two functions just return various scores for each model. The first gets the conventional scores (precision, recall, accuracy, area under the ROC) and the confusion matrix. The second returns values for the specific metrics Starbucks is interested in (NIR, IRR), using only customers predicted to receive a promotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_test, y_pred):\n",
    "    '''\n",
    "    get scores for the fitted models\n",
    "    inputs:\n",
    "    y_test = true labels\n",
    "    y_preds = model predictions\n",
    "    \n",
    "    returns: none\n",
    "    '''\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    print('confusion matrix:\\n', cm)\n",
    "    print('precision: {:.5f}; recall: {:.5f}, accuracy: {:.5f}'.format(prec, rec, acc))\n",
    "    print('roc_auc: {:.5f}'.format(auc))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score2(df, promo_pred_col = 'promo_cd'):\n",
    "    '''\n",
    "    Calculate the scoring metrics defined by Starbucks\n",
    "    input:\n",
    "    df = dataframe of features **only** for those we predicted should receive a promotion\n",
    "    promo_pred_col : the column categorizing whether or not the subject received a promotion \n",
    "                     instead of using the original \"Promotion\", I used its binary recode (0 = No, 1 = Yes)\n",
    "    '''\n",
    "    n_treat       = df.loc[df[promo_pred_col] == 1,:].shape[0]\n",
    "    n_control     = df.loc[df[promo_pred_col] == 0,:].shape[0]\n",
    "    n_treat_purch = df.loc[df[promo_pred_col] == 1, 'purchase'].sum()\n",
    "    n_ctrl_purch  = df.loc[df[promo_pred_col] == 0, 'purchase'].sum()\n",
    "    irr = n_treat_purch / n_treat - n_ctrl_purch / n_control\n",
    "    nir = 10 * n_treat_purch - 0.15 * n_treat - 10 * n_ctrl_purch\n",
    "    print('IRR: {:.5f}; NIR: {:.5f}'.format(irr, nir))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`class_weight = balanced` will weight the samples inversely proportionally to their prevalence in the data. So here, `promo+purch = 1` will be heavily weighted due to its rarity. Helps to account for the imbalance in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of what happens if we don't use a strategy like class weights or over/under-sampling to account for the imbalance. I did this the first go-round with these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      " [[27910     0]\n",
      " [  240     0]]\n",
      "precision: 0.00000; recall: 0.00000, accuracy: 0.99147\n",
      "roc_auc: 0.50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umahp/data_science/dsenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "log_mod_unwt = LogisticRegression(max_iter = 200)\n",
    "log_mod_unwt.fit(X_train2, y_train)\n",
    "y_pred_unwt = log_mod_unwt.predict(X_test2)\n",
    "get_scores(y_test, y_pred_unwt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an imbalanced dataset like this, the classic mistake (which I made) would be to look only at the accuracy, or at the p-value for the regression coefficients, and think the model is great. However, as you can see, it completely ignores the minority class. Since that's the class we're interested in, the model is effective useless. We can't even calculate NIR & IRR because we haven't predicted that **anyone** should receive a promotion.\n",
    "\n",
    "So now let's see what it looks like when we turn on the class weighting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      " [[15322 12588]\n",
      " [   64   176]]\n",
      "precision: 0.01379; recall: 0.73333, accuracy: 0.55055\n",
      "roc_auc: 0.64116\n"
     ]
    }
   ],
   "source": [
    "log_mod = LogisticRegression(max_iter = 200, class_weight = 'balanced')\n",
    "log_mod.fit(X_train2, y_train)\n",
    "y_pred1 = log_mod.predict(X_test2)\n",
    "get_scores(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask X_test for only those predicted to receive a promotion\n",
    "score_df = X_test.iloc[np.where(y_pred1 == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRR: 0.02040; NIR: 343.45000\n"
     ]
    }
   ],
   "source": [
    "score2(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is lots of mis-classification, with tons of false positives, but at least the model is predicting some customers in the promotion group. Let's see if we can do better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if interaction terms improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn_intr = X_train2.copy()\n",
    "X_trn_intr['V13xV3'] = X_trn_intr['V1_3'] * X_trn_intr['V3']\n",
    "X_trn_intr['V13x42'] = X_trn_intr['V1_3'] * X_trn_intr['V4_2']\n",
    "X_trn_intr['V13x52'] = X_trn_intr['V1_3'] * X_trn_intr['V5_2']\n",
    "X_trn_intr['V3x42'] = X_trn_intr['V3'] * X_trn_intr['V4_2']\n",
    "X_trn_intr['V3x52'] = X_trn_intr['V3'] * X_trn_intr['V5_2']\n",
    "X_trn_intr['V42x52'] = X_trn_intr['V4_2'] * X_trn_intr['V5_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst_intr = X_test2.copy()\n",
    "X_tst_intr['V13xV3'] = X_tst_intr['V1_3'] * X_tst_intr['V3']\n",
    "X_tst_intr['V13x42'] = X_tst_intr['V1_3'] * X_tst_intr['V4_2']\n",
    "X_tst_intr['V13x52'] = X_tst_intr['V1_3'] * X_tst_intr['V5_2']\n",
    "X_tst_intr['V3x42'] = X_tst_intr['V3'] * X_tst_intr['V4_2']\n",
    "X_tst_intr['V3x52'] = X_tst_intr['V3'] * X_tst_intr['V5_2']\n",
    "X_tst_intr['V42x52'] = X_tst_intr['V4_2'] * X_tst_intr['V5_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1_3</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4_2</th>\n",
       "      <th>V5_2</th>\n",
       "      <th>V13xV3</th>\n",
       "      <th>V13x42</th>\n",
       "      <th>V13x52</th>\n",
       "      <th>V3x42</th>\n",
       "      <th>V3x52</th>\n",
       "      <th>V42x52</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42450</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.732194</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.732194</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.732194</td>\n",
       "      <td>-0.732194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39436</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.385883</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.385883</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49424</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.126150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17107</th>\n",
       "      <td>0</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56521</th>\n",
       "      <td>0</td>\n",
       "      <td>0.220161</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220161</td>\n",
       "      <td>0.220161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1_3        V3  V4_2  V5_2    V13xV3  V13x42  V13x52     V3x42  \\\n",
       "42450     1 -0.732194     1     1 -0.732194       1       1 -0.732194   \n",
       "39436     0 -0.385883     1     0 -0.000000       0       0 -0.385883   \n",
       "49424     0 -0.126150     0     0 -0.000000       0       0 -0.000000   \n",
       "17107     0  0.133583     1     0  0.000000       0       0  0.133583   \n",
       "56521     0  0.220161     1     1  0.000000       0       0  0.220161   \n",
       "\n",
       "          V3x52  V42x52  \n",
       "42450 -0.732194       1  \n",
       "39436 -0.000000       0  \n",
       "49424 -0.000000       0  \n",
       "17107  0.000000       0  \n",
       "56521  0.220161       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1_3</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4_2</th>\n",
       "      <th>V5_2</th>\n",
       "      <th>V13xV3</th>\n",
       "      <th>V13x42</th>\n",
       "      <th>V13x52</th>\n",
       "      <th>V3x42</th>\n",
       "      <th>V3x52</th>\n",
       "      <th>V42x52</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51895</th>\n",
       "      <td>0</td>\n",
       "      <td>0.220161</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51955</th>\n",
       "      <td>1</td>\n",
       "      <td>0.653050</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65305</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.653050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11131</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.385883</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.385883</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56386</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.299306</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.299306</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.039572</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.039572</td>\n",
       "      <td>-0.039572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1_3        V3  V4_2  V5_2   V13xV3  V13x42  V13x52     V3x42  \\\n",
       "51895     0  0.220161     0     1  0.00000       0       0  0.000000   \n",
       "51955     1  0.653050     1     0  0.65305       1       0  0.653050   \n",
       "11131     0 -0.385883     1     0 -0.00000       0       0 -0.385883   \n",
       "56386     0 -0.299306     1     0 -0.00000       0       0 -0.299306   \n",
       "5865      0 -0.039572     1     1 -0.00000       0       0 -0.039572   \n",
       "\n",
       "          V3x52  V42x52  \n",
       "51895  0.220161       0  \n",
       "51955  0.000000       0  \n",
       "11131 -0.000000       0  \n",
       "56386 -0.000000       0  \n",
       "5865  -0.039572       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_trn_intr.head())\n",
    "display(X_tst_intr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      " [[14849 13061]\n",
      " [   59   181]]\n",
      "precision: 0.01367; recall: 0.75417, accuracy: 0.53393\n",
      "roc_auc: 0.64310\n",
      "IRR: 0.02022; NIR: 346.25000\n"
     ]
    }
   ],
   "source": [
    "# model including the 6 interaction terms\n",
    "log_mod2 = LogisticRegression(max_iter = 200, class_weight = 'balanced')\n",
    "log_mod2.fit(X_trn_intr, y_train)\n",
    "y_pred2 = log_mod2.predict(X_tst_intr)\n",
    "get_scores(y_test, y_pred2)\n",
    "score_df = X_test.iloc[np.where(y_pred2 == 1)] \n",
    "score2(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IRR is slightly worse, NIR is slightly better. Precision is a little worse. Will not use the interactions since minimal contribution and may lead to overfitting since adds 6 more variables.\n",
    "\n",
    "Try cross-validation tuning of the C-parameter. Will use model without interactions. Use precision as the score metric to see if can minimize the false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogRegCV optimal C: [0.00077426]\n"
     ]
    }
   ],
   "source": [
    "log_modcv = LogisticRegressionCV(max_iter = 200, scoring = 'precision', class_weight='balanced', n_jobs = -1)\n",
    "log_modcv.fit(X_train2, y_train)\n",
    "y_predlogcv = log_modcv.predict(X_test2)\n",
    "print('LogRegCV optimal C:', log_modcv.C_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      " [[14887 13023]\n",
      " [   62   178]]\n",
      "precision: 0.01348; recall: 0.74167, accuracy: 0.53517\n",
      "roc_auc: 0.63753\n",
      "IRR: 0.01963; NIR: 307.90000\n"
     ]
    }
   ],
   "source": [
    "get_scores(y_test, y_predlogcv)\n",
    "score_df = X_test.iloc[np.where(y_predlogcv == 1)] \n",
    "score2(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse than the un-tuned model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a machine-learning model. Will start with SVM.  \n",
    "Will use the data without the interactions since they didn't seem to help.\n",
    "Again, will use `balanced` class weight to adjust for the imbalance.\n",
    "I did a lot of manual tuning on the parameters and what's below was my best for `C` and `gamma`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in exploratory analyses, these were the best manually tuned params for SVC\n",
    "clf = SVC(class_weight='balanced', C=5, gamma=2)\n",
    "clf.fit(X_train3, y_train) # use the set with V3 normalized\n",
    "y_pred3 = clf.predict(X_test3) # normalized V3 again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      " [[14102 13808]\n",
      " [   60   180]]\n",
      "precision: 0.01287; recall: 0.75000, accuracy: 0.50735\n",
      "roc_auc: 0.62763\n",
      "IRR: 0.01849; NIR: 247.75000\n"
     ]
    }
   ],
   "source": [
    "get_scores(y_test, y_pred3)\n",
    "score_df = X_test.iloc[np.where(y_pred3 == 1)] \n",
    "score2(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is slightly worse than logistic regression, although hyperparameters could probably be more finely tuned.\n",
    "\n",
    "Will try some tuning with `GridSearchCV`.  \n",
    "The narrow range here is after trying other experiments with wider ranges that didn't improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "\n",
      "Best GridSearch Parameters: {'C': 7, 'class_weight': 'balanced', 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "# best manually tuned params were C=5, gamma=2. Initially tried wide-ranging grid search \n",
    "# but didn't reaveal anything better going far outside these #s so sticking close\n",
    "clf = SVC()\n",
    "parameters = [{'C': [2, 3, 5, 7],\n",
    "               'gamma': [1, 1.5, 2, 2.5],\n",
    "               'class_weight':  ['balanced']\n",
    "              }]\n",
    "\n",
    "gscv = GridSearchCV(clf, param_grid=parameters, cv = 3, scoring = 'precision', verbose = 2, n_jobs = -1)\n",
    "gscv.fit(X_train2, y_train)\n",
    "y_predgs = gscv.predict(X_test2)\n",
    "print('\\nBest GridSearch Parameters:', gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      " [[14292 13618]\n",
      " [   63   177]]\n",
      "precision: 0.01283; recall: 0.73750, accuracy: 0.51400\n",
      "roc_auc: 0.62479\n",
      "IRR: 0.01896; NIR: 279.75000\n"
     ]
    }
   ],
   "source": [
    "get_scores(y_test, y_predgs)\n",
    "score_df = X_test.iloc[np.where(y_predgs == 1)] \n",
    "score2(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing on precision did improve IRR & NIR. But still not as good as the logistic regression model. It did select the highest C and lowest gamma, tho, so let's expand athose ranges a little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 3\n",
      "n_required_iterations: 3\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 6264\n",
      "max_resources_: 56384\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 20\n",
      "n_resources: 6264\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 7\n",
      "n_resources: 18792\n",
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 3\n",
      "n_resources: 56376\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "\n",
      "Best GridSearch Parameters: {'C': 16, 'class_weight': 'balanced', 'gamma': 0.25}\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "parameters = [{'C': [8, 16, 32, 64],\n",
    "               'gamma': [0.1, 0.25, 0.75, 0.9, 0.95],\n",
    "               'class_weight':  ['balanced']\n",
    "              }]\n",
    "#try halving grid search to speed up\n",
    "gscv = HalvingGridSearchCV(clf, param_grid=parameters, cv = 3, scoring = 'precision', verbose = 2, n_jobs = -1)\n",
    "gscv.fit(X_train2, y_train)\n",
    "y_predgs = gscv.predict(X_test2)\n",
    "print('\\nBest GridSearch Parameters:', gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      " [[13198 14712]\n",
      " [   51   189]]\n",
      "precision: 0.01268; recall: 0.78750, accuracy: 0.47556\n",
      "roc_auc: 0.63019\n",
      "IRR: 0.01826; NIR: 242.50000\n"
     ]
    }
   ],
   "source": [
    "get_scores(y_test, y_predgs)\n",
    "score_df = X_test.iloc[np.where(y_predgs == 1)] \n",
    "score2(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That found values in the middle of the ranges, but precision on test set is worse. Logistic regression is still in the lead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try an XGBoost algorithm. Here `scale_pos_weight` is the weight for the \"positive\" samples (`promo+purch = 1`).\n",
    "Will make that the inverse of its prevalence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_wt:  117.24549237170596\n"
     ]
    }
   ],
   "source": [
    "xgb_wt = train_data.shape[0]/train_data['promo+purch'].sum()\n",
    "print('xgb_wt: ', xgb_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      " [[16739 11171]\n",
      " [   99   141]]\n",
      "precision: 0.01246; recall: 0.58750, accuracy: 0.59964\n",
      "roc_auc: 0.59362\n",
      "IRR: 0.01787; NIR: 167.10000\n"
     ]
    }
   ],
   "source": [
    "# this doesn't have an option for precision, so using auc instead\n",
    "xgb = XGBClassifier(scale_pos_weight = xgb_wt, use_label_encoder = False, objective = 'binary:logistic',\\\n",
    "                    max_delta_step = 5, subsample = 0.5, eval_metric = 'auc')\n",
    "xgb.fit(X_train2, y_train)\n",
    "y_predxgb = xgb.predict(X_test2)\n",
    "get_scores(y_test, y_predxgb)\n",
    "score_df = X_test.iloc[np.where(y_predxgb == 1)] \n",
    "score2(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse than logistic, and worse than the SVM due to more false negatives. But no tuning done.\n",
    "\n",
    "Try to tune XGBoost. Lots of parameters, may take some time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 696\n",
      "max_resources_: 56384\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 216\n",
      "n_resources: 696\n",
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 72\n",
      "n_resources: 2088\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 24\n",
      "n_resources: 6264\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 8\n",
      "n_resources: 18792\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 3\n",
      "n_resources: 56376\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "\n",
      "Best GridSearch Parameters: {'eta': 0.1, 'gamma': 10, 'max_delta_step': 5, 'max_depth': 2, 'min_child_weight': 100, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# for ref on hyperparams in XGB, see https://www.kaggle.com/prashant111/a-guide-on-xgboost-hyperparameters-tuning\n",
    "clf = XGBClassifier(scale_pos_weight = xgb_wt, use_label_encoder = False, objective = 'binary:logistic', \\\n",
    "                    eval_metric = 'auc')\n",
    "parameters = [{'eta': [0.05, 0.1, 0.3],\n",
    "               'gamma':  [0, 10],\n",
    "               'max_depth':  [2, 4, 6],\n",
    "               'min_child_weight':  [0, 10, 100],\n",
    "               'max_delta_step': [0, 5],\n",
    "               'subsample': [0.5, 1.0]\n",
    "              }]\n",
    "# try halving grid search here to speed things up\n",
    "gsxgb = HalvingGridSearchCV(clf, param_grid = parameters, cv = 3, scoring = 'roc_auc', verbose = 2, n_jobs = -1)\n",
    "gsxgb.fit(X_train2, y_train)\n",
    "y_predgsxgb = gsxgb.predict(X_test2)\n",
    "print('\\nBest GridSearch Parameters:', gsxgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      " [[14954 12956]\n",
      " [   65   175]]\n",
      "precision: 0.01333; recall: 0.72917, accuracy: 0.53744\n",
      "roc_auc: 0.63248\n",
      "IRR: 0.01925; NIR: 282.55000\n"
     ]
    }
   ],
   "source": [
    "get_scores(y_test, y_predgsxgb)\n",
    "score_df = X_test.iloc[np.where(y_predgsxgb == 1)] \n",
    "score2(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much improved from the naive model, but still not as good as logistic regression. It's possible I didn't tune perfectly, but the other consideration is the logistic model runs in seconds, vs hours to tune the XGBoost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def promotion_strategy(df):\n",
    "    '''\n",
    "    INPUT \n",
    "    df - a dataframe with *only* the columns V1 - V7 (same as train_data)\n",
    "\n",
    "    OUTPUT\n",
    "    promotion_df - np.array with the values\n",
    "                   'Yes' or 'No' related to whether or not an \n",
    "                   individual should recieve a promotion \n",
    "                   should be the length of df.shape[0]\n",
    "                \n",
    "    Ex:\n",
    "    INPUT: df\n",
    "    \n",
    "    V1\tV2\t  V3\tV4\tV5\tV6\tV7\n",
    "    2\t30\t-1.1\t1\t1\t3\t2\n",
    "    3\t32\t-0.6\t2\t3\t2\t2\n",
    "    2\t30\t0.13\t1\t1\t4\t2\n",
    "    \n",
    "    OUTPUT: promotion\n",
    "    \n",
    "    array(['Yes', 'Yes', 'No'])\n",
    "    indicating the first two users would recieve the promotion and \n",
    "    the last should not.\n",
    "    '''\n",
    "\n",
    "    # just make the dummy vars we need\n",
    "    df['V1_3'] = 0\n",
    "    df['V1_3'].loc[df['V1'] == 3] = 1\n",
    "    df['V5_2'] = 0\n",
    "    df['V5_2'].loc[df['V5'] == 2] = 1\n",
    "    df['V4_2'] = 0\n",
    "    df['V4_2'].loc[df['V4'] == 2] = 1\n",
    "    df['V5_2'] = 0\n",
    "    df['V5_2'].loc[df['V5'] == 2] = 1\n",
    "  \n",
    "    X_final = df[['V1_3', 'V3', 'V4_2', 'V5_2']] \n",
    "    display(X_final.head())\n",
    "    \n",
    "    # this is the 1st logistic regression model, which gave the best overall results\n",
    "    promo = log_mod.predict(X_final)\n",
    "    print('promo', promo.sum(), promo.shape[0])\n",
    "    promotion = np.where(promo == 1, 'Yes', 'No')\n",
    "        \n",
    "    return promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-113-a0d905fa069a>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['V1_3'] = 0\n",
      "/home/umahp/data_science/dsenv/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/home/umahp/data_science/dsenv/lib/python3.8/site-packages/pandas/core/indexing.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n",
      "<ipython-input-113-a0d905fa069a>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['V5_2'] = 0\n",
      "/home/umahp/data_science/dsenv/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/home/umahp/data_science/dsenv/lib/python3.8/site-packages/pandas/core/indexing.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n",
      "/home/umahp/data_science/dsenv/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/home/umahp/data_science/dsenv/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1_3</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4_2</th>\n",
       "      <th>V5_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.172517</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.653050</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.597972</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.078506</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.479895</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1_3        V3  V4_2  V5_2\n",
       "0     0  1.172517     0     0\n",
       "1     0  0.653050     1     1\n",
       "2     0 -1.597972     1     0\n",
       "3     0 -1.078506     1     0\n",
       "4     0  0.479895     1     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promo 18784 41650\n",
      "Nice job!  See how well your strategy worked on our test data below!\n",
      "\n",
      "Your irr with this strategy is 0.0203.\n",
      "\n",
      "Your nir with this strategy is 475.60.\n",
      "We came up with a model with an irr of 0.0188 and an nir of 189.45 on the test set.\n",
      "\n",
      " How did you do?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.020253321162268925, 475.60000000000014)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will test your results, and provide you back some information \n",
    "# on how well your promotion_strategy will work in practice\n",
    "\n",
    "test_results(promotion_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So looks like I at least did better than their benchmark, though I probably took waaaay longer to get this done than their interview candidates get..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsenv",
   "language": "python",
   "name": "dsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
